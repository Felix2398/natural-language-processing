{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef646414",
   "metadata": {},
   "source": [
    "# Worksheet 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa3dfb2",
   "metadata": {},
   "source": [
    "## Task 1\n",
    "\n",
    "Write a regular expression that can:\n",
    "\n",
    "(a) Validate German ZIP codes: `[0-9]{5}`\n",
    "\n",
    "(b) Detect academic titles (Prof., Prof, Dr., Dr, , B.Sc., BSc, M.Sc., MSc, B.A., ...): `(Prof|Dr|((B|M)\\\\.?(Sc|A)))\\\\.?`\n",
    "\n",
    "(c) Test whether a binary string (i.e. a string that just contains 0s and 1s) contains the substring \"01\" and \"10\" an equal number of times: not possible with regular expressions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd8712e",
   "metadata": {},
   "source": [
    "## Task 2\n",
    "\n",
    "Calculate the minimum edit distance between \"color\" and \"colour\" with the algorithm introduced in the lecture (provide the full table).\n",
    "\n",
    "(a) Assume the cost of all transactions to be 1.\n",
    "\n",
    "|   |   | c | o | l | o | u | r |\n",
    "|---|---|---|---|---|---|---|---|\n",
    "|   | 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
    "| c | 1 | 0 | 1 | 2 | 3 | 4 | 5 |\n",
    "| o | 2 | 1 | 0 | 1 | 2 | 3 | 4 |\n",
    "| l | 3 | 2 | 1 | 0 | 1 | 2 | 3 |\n",
    "| o | 4 | 3 | 2 | 1 | 0 | 1 | 2 |\n",
    "| r | 5 | 4 | 3 | 2 | 1 | 1 | 1 |\n",
    "\n",
    "(b) How does the table change if the costs for replacement is 2 (i.e. equal to the costs of a deletion and insertion)?\n",
    "\n",
    "|   |   | c | o | l | o | u | r |\n",
    "|---|---|---|---|---|---|---|---|\n",
    "|   | 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
    "| c | 1 | 0 | 1 | 2 | 3 | 4 | 5 |\n",
    "| o | 2 | 1 | 0 | 1 | 2 | 3 | 4 |\n",
    "| l | 3 | 2 | 1 | 0 | 1 | 2 | 3 |\n",
    "| o | 4 | 3 | 2 | 1 | 0 | 1 | 2 |\n",
    "| r | 5 | 4 | 3 | 2 | 1 | 2 | 1 |\n",
    "\n",
    "Only changes the u,r cell and doesnt effect the final result."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98fc8cf3",
   "metadata": {},
   "source": [
    "## Task 3\n",
    "\n",
    "Implement the minimum edit distance algorithm introduced in the lecture in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fec8a64d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def min_edit_distance(source, target, ins_cost=1, del_cost=1, sub_cost=1):\n",
    "    n = len(source) + 1\n",
    "    m = len(target) + 1\n",
    "    d = np.zeros((n,m), dtype=int)\n",
    "\n",
    "    for i in range(1, n):\n",
    "        d[i ,0] = d[i - 1, 0] + del_cost\n",
    "    \n",
    "    for j in range(1, m):\n",
    "        d[0, j] = d[0, j - 1] + ins_cost\n",
    "    \n",
    "    for j in range(1, m):\n",
    "        for i in range(1, n):\n",
    "            if source[i - 1] == target[j - 1]:\n",
    "                d[i, j] = d[i - 1, j - 1]\n",
    "            else:\n",
    "                d[i, j] = min(d[i, j - 1] + ins_cost, d[i - 1, j] + del_cost, d[i - 1, j - 1] + sub_cost)\n",
    "\n",
    "    return d[n - 1, m - 1]\n",
    "\n",
    "print(min_edit_distance(\"color\", \"colour\"))\n",
    "print(min_edit_distance(\"color\", \"colour\", sub_cost=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "048741b7",
   "metadata": {},
   "source": [
    "## Task 4\n",
    "\n",
    "Use the full rule set of the [Porter Stemmer](https://www.inf.fu-berlin.de/lehre/WS01/netbasedIS/vortraege/stem_porter.html) to manually stem the following words. Show your work (i.e. write down the intermediate steps).\n",
    "\n",
    "(a) enshittification\n",
    "\n",
    "- Step 2: (m>0) ATION -> ATE: enshittificate\n",
    "- Step 3: (m>0) ICATE -> IC: enshittific\n",
    "- Step 4: (m>1) IC -> : enshittif\n",
    "\n",
    "(b) congratulations\n",
    "\n",
    "- Step 1a: S -> : congratulation\n",
    "- Step 2: (m>0) ATION -> ATE: congratulate\n",
    "- Step 4: (m>1) ATE -> : congratul\n",
    "\n",
    "(c) necessity\n",
    "\n",
    "- Step 1c: (\\*v\\*) Y -> I: necessiti\n",
    "- Step 4: (m>1) ITI   -> : necess\n",
    "\n",
    "(d) bare: Is the final stem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2809b25",
   "metadata": {},
   "source": [
    "## Task 5\n",
    "\n",
    "For the following sentences: \"I own multiple cats.\", \"Marburg is a nice city.\", \"It’s fairly cold in here.\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "4647953b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\felix\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\felix\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     C:\\Users\\felix\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "# setup\n",
    "import nltk\n",
    "from nltk.stem import *\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tag import pos_tag\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger_eng')\n",
    "\n",
    "sentences = [\"I own multiple cats.\", \"Marburg is a nice city.\", \"It's fairly cold in here.\"]\n",
    "tokens = [word_tokenize(sentence) for sentence in sentences]\n",
    "\n",
    "porter = PorterStemmer()\n",
    "snowball = SnowballStemmer('english')\n",
    "wnl = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62336730",
   "metadata": {},
   "source": [
    "\n",
    "(a) Use the popular NLP library NLTK to stem the sentences with the [Porter and the Snowball stemmer](https://www.nltk.org/howto/stem.html). What do you notice? Hint: You will need to tokenize the sentences, you can use the [word_tokenize function](https://www.nltk.org/api/nltk.tokenize.word_tokenize.html) of NLTK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "841dc311",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Porter:    [['i', 'own', 'multipl', 'cat', '.'], ['marburg', 'is', 'a', 'nice', 'citi', '.'], ['it', \"'s\", 'fairli', 'cold', 'in', 'here', '.']]\n",
      "Snowball:  [['i', 'own', 'multipl', 'cat', '.'], ['marburg', 'is', 'a', 'nice', 'citi', '.'], ['it', \"'s\", 'fair', 'cold', 'in', 'here', '.']]\n"
     ]
    }
   ],
   "source": [
    "# a)\n",
    "result_porter = [[porter.stem(plural) for plural in plurals] for plurals in tokens]\n",
    "result_snowball = [[snowball.stem(plural) for plural in plurals] for plurals in tokens]\n",
    "\n",
    "print('Porter:   ', result_porter)\n",
    "print('Snowball: ', result_snowball)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "709449a8",
   "metadata": {},
   "source": [
    "(b) Find three additional sentences which are stemmed differently by the Porter and Snowball stemmer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98659672",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Porter:    [['quickli'], ['gener'], ['rel']]\n",
      "Snowball:  [['quick'], ['generous'], ['relat']]\n"
     ]
    }
   ],
   "source": [
    "words = [\"quickly\", \"generously\", \"relativity\"]\n",
    "tokens_words = [word_tokenize(word) for word in words]\n",
    "\n",
    "result_porter = [[porter.stem(plural) for plural in plurals] for plurals in tokens_words]\n",
    "result_snowball = [[snowball.stem(plural) for plural in plurals] for plurals in tokens_words]\n",
    "\n",
    "print('Porter:   ', result_porter)\n",
    "print('Snowball: ', result_snowball)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d673e049",
   "metadata": {},
   "source": [
    "(c) NLTK also supports lemmatization using the [WordNetLemmatizer4](https://www.nltk.org/api/nltk.stem.WordNetLemmatizer.html). Use the lemmatize function of the WordNetLemmatizer and pass the tokens as only parameter, what do you observe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b635adb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:    [['I', 'own', 'multiple', 'cats', '.'], ['Marburg', 'is', 'a', 'nice', 'city', '.'], ['It', \"'s\", 'fairly', 'cold', 'in', 'here', '.']]\n",
      "Lemmatized:  [['I', 'own', 'multiple', 'cat', '.'], ['Marburg', 'is', 'a', 'nice', 'city', '.'], ['It', \"'s\", 'fairly', 'cold', 'in', 'here', '.']]\n"
     ]
    }
   ],
   "source": [
    "print(\"Original:   \", tokens)\n",
    "print(\"Lemmatized: \", [[wnl.lemmatize(plural) for plural in plurals] for plurals in tokens])\n",
    "\n",
    "# It only removes plurals, in this case \"cats\" -> \"cat\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9dcd3f9",
   "metadata": {},
   "source": [
    "It only removes plurals, in this case cats -> cat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdfec0c3",
   "metadata": {},
   "source": [
    "(d) Now use NLTK’s [PoS Tagger](https://www.nltk.org/api/nltk.tag.pos_tag.html) to use the lemmatize function with two parameters, the token and its PoS. Hint: You will have to convert the PoS tags to fit the tags expected by the lemmatizer function. What changes do you observe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46b4be0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:    [['I', 'own', 'multiple', 'cats', '.'], ['Marburg', 'is', 'a', 'nice', 'city', '.'], ['It', \"'s\", 'fairly', 'cold', 'in', 'here', '.']]\n",
      "Lemmatized:  [['I', 'own', 'multiple', 'cat', '.'], ['Marburg', 'be', 'a', 'nice', 'city', '.'], ['It', \"'s\", 'fairly', 'cold', 'in', 'here', '.']]\n"
     ]
    }
   ],
   "source": [
    "# d)\n",
    "tags = [pos_tag(sentece) for sentece in tokens]\n",
    "\n",
    "def get_wordnet_pos(tag):\n",
    "    if tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN \n",
    "\n",
    "print(\"Original:   \", tokens)\n",
    "print(\"Lemmatized: \", [[wnl.lemmatize(word, get_wordnet_pos(tag)) for (word, tag) in sentence] for sentence in tags])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e5f755d",
   "metadata": {},
   "source": [
    "Plurals get transformed into singulars (cats -> cat) and verbs get transfromed into their base from (is -> be)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2946f45",
   "metadata": {},
   "source": [
    "## Task 6\n",
    "\n",
    "Analyse the sentiment of the sentence \"We waited one hour in line to check in for our flight. Juuust great, exactly what you need to start of your vacation!\" using:\n",
    "\n",
    "(a) The Python library [TextBlob](https://textblob.readthedocs.io/en/dev/index.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "15ab109e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.55625\n"
     ]
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "text = 'We waited one hour in line to check in for our flight. Juuust great, exactly what you need to start of your vacation!'\n",
    "\n",
    "blob = TextBlob(text)\n",
    "for sentence in blob.sentences:\n",
    "    print(sentence.sentiment.polarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "406977b4",
   "metadata": {},
   "source": [
    "Interpretation of results: 0.0 -> Neutral sentiment, 0.55625 -> fairly subjective"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9139b17",
   "metadata": {},
   "source": [
    "(b) Two different LLMs (provide your prompt and the results)\n",
    "\n",
    "*Prompt*: Analyse the sentiment of the sentence \"We waited one hour in line to check in for our flight. Juuust great, exactly what you need to start of your vacation!\"\n",
    "\n",
    "*ChatGPT 4o*:\n",
    "\n",
    "The sentiment of the sentence: \"We waited one hour in line to check in for our flight. Juuust great, exactly what you need to start of your vacation!\" is sarcastic and negative.\n",
    "\n",
    "Analysis:\n",
    "\n",
    "- Literal content: Waiting an hour in line to check in for a flight is generally an unpleasant experience.\n",
    "- Tone and phrasing: The exaggerated spelling of “Juuust great” and the phrase “exactly what you need to start off your vacation” are classic indicators of sarcasm. These expressions are often used ironically to imply the opposite of the literal words.\n",
    "- Implied sentiment: Despite the superficially positive words (“great”, “what you need”), the context and delivery suggest frustration or dissatisfaction.\n",
    "\n",
    "Conclusion: The speaker is expressing frustration and displeasure with a sarcastic tone, making the overall sentiment negative.\n",
    "\n",
    "*Deepseek*:\n",
    "\n",
    "The sentiment of the sentence is negative and expresses sarcasm and frustration.\n",
    "\n",
    "Breakdown:\n",
    " - \"We waited one hour in line to check in for our flight.\": This sets a negative tone, as long waiting times are generally frustrating.\n",
    "- \"Juuust great, exactly what you need to start off your vacation!\": The exaggerated spelling of \"Juuust\" and the phrase \"exactly what you need\" are heavily sarcastic, implying the opposite of what is stated. The speaker is clearly unhappy about the situation, as this is not an ideal way to begin a vacation.\n",
    "\n",
    "Conclusion: The overall sentiment is negative, with a tone of sarcastic disappointment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b1478e",
   "metadata": {},
   "source": [
    "(c) What do you observe?\n",
    "\n",
    "TextBlob struggles with detecting sarcasm, while modern LLMs are able to catch it."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
