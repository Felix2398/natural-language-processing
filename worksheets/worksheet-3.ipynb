{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b291a396",
   "metadata": {},
   "source": [
    "# Worksheet 3\n",
    "\n",
    "## Task 1\n",
    "\n",
    "Given the following training set:\n",
    "\n",
    "```\n",
    "<s> language models model language </s>\n",
    "<s> model language as a language model </s>\n",
    "<s> language models as a model </s>\n",
    "```\n",
    "\n",
    "(a) What is the size of the vocabulary in the data?\n",
    "\n",
    "[\\<s\\>, language, models, model, as, a, \\</s\\>] -> 7\n",
    "\n",
    "(b) Calculate the probabilities of all unigrams.\n",
    "\n",
    "- P(\\</s\\>) = 3/21\n",
    "- P(language) = 5/21\n",
    "- P(models) = 2/21\n",
    "- P(model) = 4/21\n",
    "- P(as) = 2/21\n",
    "- P(a) = 2/21\n",
    "- P(\\</s\\>) = 3/21\n",
    "\n",
    "(c) What are the probability estimates for the following bigrams using MLE: language model, language models, models language, model models, models model?\n",
    "\n",
    "- P(model | language) = 1/5\n",
    "- P(models | language) = 2/5\n",
    "- P(language | models) = 0/2\n",
    "- P(models | model) = 0/4\n",
    "- P(model | models) = 1/2\n",
    "\n",
    "(d) What is the probability estimate for the trigram using MLE: model language as?\n",
    "\n",
    "- P(as | model language) = 1/2\n",
    "\n",
    "(e) Given the test sentence `<s> model language as a model </s>`, what is the perplexity of the sentence for a bigram model trained on the training data?\n",
    "\n",
    "- P(model | \\<s\\>) = 1/3\n",
    "- P(language | model) = 2/4\n",
    "- P(as | language) = 1/5\n",
    "- P(a | as) = 2/2\n",
    "- P(model | a) = 1/2\n",
    "- P(\\</s\\> | model) = 2/4\n",
    "\n",
    "$\n",
    "PP = \\sqrt[7]{\\frac{1}{0.33 \\cdot 0.5 \\cdot 0.2 \\cdot 1 \\cdot 0.5 \\cdot 0.5}} = \\sqrt[7]{\\frac{1}{0.01}} = 1.98\n",
    "$\n",
    "\n",
    "(f) Use Laplace Smoothing to smooth the probability estimates for the bigrams from task (c)\n",
    "\n",
    "- P(model | language) = 2/12\n",
    "- P(models | language) = 3/12\n",
    "- P(language | models) = 1/9\n",
    "- P(models | model) = 1/11\n",
    "- P(model | models) = 2/9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a9b9f32",
   "metadata": {},
   "source": [
    "## Task 2\n",
    "\n",
    "Write Python code that:\n",
    "\n",
    "(a) For a list of sentences (e.g. `s = [\"Language models model language\", \"Model language as a language model\", \"Language models as a model\"]`) converts each sentence into lowercase, tokenizes it, and appends a start (`<s>`) and end symbol to each (`</s>`) sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39f31ffb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['<s>', 'language', 'models', 'model', 'language', '</s>'], ['<s>', 'model', 'language', 'as', 'a', 'language', 'model', '</s>'], ['<s>', 'language', 'models', 'as', 'a', 'model', '</s>']]\n"
     ]
    }
   ],
   "source": [
    "def tokenize(sentence):\n",
    "    return ['<s>'] + sentence.lower().split() + ['</s>']\n",
    "\n",
    "s = [\"Language models model language\", \"Model language as a language model\", \"Language models as a model\"]\n",
    "t = [tokenize(sentence) for sentence in s]\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d42be6f",
   "metadata": {},
   "source": [
    "(b) Takes the output of (a) and lists all unique unigrams, bigrams, and trigrams, as well as the vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00a479b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocabulary: ['model', 'language', 'a', 'models', 'as', '</s>', '<s>']\n",
      "unigrams:   ['model', 'language', 'a', 'models', 'as', '</s>', '<s>']\n",
      "bigrams:    [('language', 'as'), ('as', 'a'), ('a', 'model'), ('language', 'model'), ('model', '</s>'), ('a', 'language'), ('language', 'models'), ('models', 'as'), ('models', 'model'), ('<s>', 'model'), ('model', 'language'), ('language', '</s>'), ('<s>', 'language')]\n",
      "trigrams:   [('<s>', 'model', 'language'), ('language', 'model', '</s>'), ('model', 'language', '</s>'), ('a', 'language', 'model'), ('models', 'model', 'language'), ('model', 'language', 'as'), ('language', 'models', 'as'), ('language', 'models', 'model'), ('models', 'as', 'a'), ('as', 'a', 'model'), ('a', 'model', '</s>'), ('<s>', 'language', 'models'), ('language', 'as', 'a'), ('as', 'a', 'language')]\n"
     ]
    }
   ],
   "source": [
    "def flatten(l):\n",
    "    return [item for sublist in l for item in sublist]\n",
    "\n",
    "def unique(l):\n",
    "    return list(set(l) )\n",
    "\n",
    "def get_bigrams(l):\n",
    "    bigrams = []\n",
    "    for i in range(1, len(l)):\n",
    "        bigrams.append((l[i - 1], l[i]))\n",
    "    return bigrams\n",
    "\n",
    "def get_trigrams(l):\n",
    "    trigrams = []\n",
    "    for i in range(2, len(l)):\n",
    "        trigrams.append((l[i - 2], l[i - 1], l[i]))\n",
    "    return trigrams\n",
    "\n",
    "vocabulary = unique(flatten(t))\n",
    "bigrams = unique(flatten(get_bigrams(sentence) for sentence in t))\n",
    "trigrams = unique(flatten(get_trigrams(sentence) for sentence in t))\n",
    "\n",
    "print('vocabulary:', vocabulary)\n",
    "print('unigrams:  ', vocabulary)\n",
    "print('bigrams:   ', bigrams)\n",
    "print('trigrams:  ', trigrams)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f1e91c",
   "metadata": {},
   "source": [
    "(c) Use the output of (b) to train a bi-gram language model. I.e. create a dict that assigns each bigram its probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6a6528ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{('language', 'as'): 0.2, ('as', 'a'): 1.0, ('a', 'model'): 0.5, ('language', 'model'): 0.2, ('model', '</s>'): 0.5, ('a', 'language'): 0.5, ('language', 'models'): 0.4, ('models', 'as'): 0.5, ('models', 'model'): 0.5, ('<s>', 'model'): 0.3333333333333333, ('model', 'language'): 0.5, ('language', '</s>'): 0.2, ('<s>', 'language'): 0.6666666666666666}\n"
     ]
    }
   ],
   "source": [
    "def train(bigrams, words):\n",
    "    probabilities = {}\n",
    "    for bigram in unique(bigrams):\n",
    "        count_bigram = bigrams.count(bigram)\n",
    "        count_word = words.count(bigram[0])\n",
    "        probabilities[bigram] = count_bigram / count_word\n",
    "    return probabilities\n",
    "\n",
    "bigrams_all = flatten(get_bigrams(sentence) for sentence in t)\n",
    "words = flatten(t)\n",
    "model = train(bigrams_all, words)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f95609f7",
   "metadata": {},
   "source": [
    "(d) Write a function that calculates the perplexity of the bigram language model on a given test set and calculate the perplexity on the sentence \"Language models party\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "75aed93a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "perplexity:  0.0030562842716315964\n"
     ]
    }
   ],
   "source": [
    "def perplexity(sentence, model):\n",
    "    token = tokenize(sentence)\n",
    "    bigrams = get_bigrams(token)\n",
    "    perplexity = 1\n",
    "    for bigram in bigrams:\n",
    "        if bigram in model:\n",
    "            perplexity *= model[bigram]\n",
    "        else:\n",
    "            perplexity *= 1/1000000\n",
    "    return perplexity ** (1 / len(token))\n",
    "\n",
    "print('perplexity: ', perplexity(\"Language models party\", model))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
